# ğŸ“About
A simple way to train a llm by using transformers and running it for chat conversations.


## ğŸ‘¨â€ğŸ’» Dependencies
MAKE SURE THAT YOU HAVE THESE MODULES INSTALLED FIRST!
> transformers  <br>
> torch<br>
> time <br>

## âœ”ï¸ How to Run
 
1ï¸âƒ£Save your dataset as dataset.txt .

2ï¸âƒ£Run ```train_llm.py``` and wait till it finishes.





3ï¸âƒ£Run ```run_llm.py``` to run the llm and chat with it.


## â„¹ï¸ Info

Also while training, cache file like ``cached_lm_GPT2Tokenizer_16_dataset.txt`` as uploaded above is created, do not edit or move it. Also you only need to download ``train_llm.py`` and ``run_llm.py`` files and make sure that you install dependencies."


## ğŸ’¡ Tips

ğŸŸ¢Make sure your dataset is organized, formatted with high quality data <br>
ğŸŸ¢If you are training on low end system like in my case,set epoc and save step values to low or if you have plenty of time you can mess aroun <br>
ğŸŸ¢Make sure your dataset isnt too small <br>
ğŸŸ¢If you get any kind of warning while running,dont panic just wait for the llms response,do not panic <br>


 




## ğŸ“º Updates
<h2>completed</h2> 

